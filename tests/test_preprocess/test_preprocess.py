# encoding=utf-8
# Author: Yu-Lun Chiang
# Description: Test preprocess functions

import logging

logger = logging.getLogger(__name__)


def assertEquals(
    content_text, expected_content_text, n_gram_text, expected_n_gram_text
):
    assert len(content_text) == len(expected_content_text)
    assert content_text == expected_content_text

    assert len(n_gram_text) == len(expected_n_gram_text)
    assert len(n_gram_text[0]) == len(expected_n_gram_text[0])
    assert n_gram_text == expected_n_gram_text


def test_preprocess(testcase2, extractor):
    tokenized_text = testcase2["tokenized_text"]
    content_text, n_gram_text = extractor._preprocess(tokenized_text)
    expected_content_text = [
        (1, "進擊"),
        (3, "巨人"),
        (6, "日語"),
        (8, "進撃"),
        (9, "の"),
        (10, "巨人"),
        (13, "日本"),
        (14, "漫畫家"),
        (15, "諫山"),
        (16, "創"),
        (17, "創作"),
        (19, "漫畫"),
        (20, "作品"),
        (22, "漫畫"),
        (24, "2009年"),
        (25, "9月"),
        (27, "2021年"),
        (28, "4月間"),
        (30, "講談社"),
        (33, "冊"),
        (34, "少年"),
        (35, "Magazine"),
        (38, "連載"),
        (40, "故事"),
        (41, "建立"),
        (43, "人類"),
        (45, "巨人"),
        (47, "衝突"),
        (50, "人類"),
        (51, "居住"),
        (54, "高"),
        (55, "牆"),
        (56, "包圍"),
        (58, "城市"),
        (60, "對抗"),
        (62, "食"),
        (65, "巨人"),
    ]
    expected_n_gram_text = [
        [(1, "進擊")],
        [(3, "巨人")],
        [(6, "日語")],
        [(8, "進撃")],
        [(9, "の")],
        [(10, "巨人")],
        [(13, "日本")],
        [(14, "漫畫家")],
        [(15, "諫山")],
        [(16, "創")],
        [(17, "創作")],
        [(19, "漫畫")],
        [(20, "作品")],
        [(22, "漫畫")],
        [(24, "2009年")],
        [(25, "9月")],
        [(27, "2021年")],
        [(28, "4月間")],
        [(30, "講談社")],
        [(33, "冊")],
        [(34, "少年")],
        [(35, "Magazine")],
        [(38, "連載")],
        [(40, "故事")],
        [(41, "建立")],
        [(43, "人類")],
        [(45, "巨人")],
        [(47, "衝突")],
        [(50, "人類")],
        [(51, "居住")],
        [(54, "高")],
        [(55, "牆")],
        [(56, "包圍")],
        [(58, "城市")],
        [(60, "對抗")],
        [(62, "食")],
        [(65, "巨人")],
    ]

    assertEquals(content_text, expected_content_text, n_gram_text, expected_n_gram_text)


def test_preprocess_add_custom_stopwords(testcase2, extractor):
    tokenized_text = testcase2["tokenized_text"]
    content_text, n_gram_text = extractor._preprocess(
        tokenized_text,
        stopwords=["進擊", "巨人", "人類"],
    )
    expected_content_text = [
        (6, "日語"),
        (8, "進撃"),
        (9, "の"),
        (13, "日本"),
        (14, "漫畫家"),
        (15, "諫山"),
        (16, "創"),
        (17, "創作"),
        (19, "漫畫"),
        (20, "作品"),
        (22, "漫畫"),
        (24, "2009年"),
        (25, "9月"),
        (27, "2021年"),
        (28, "4月間"),
        (30, "講談社"),
        (33, "冊"),
        (34, "少年"),
        (35, "Magazine"),
        (38, "連載"),
        (40, "故事"),
        (41, "建立"),
        (47, "衝突"),
        (51, "居住"),
        (54, "高"),
        (55, "牆"),
        (56, "包圍"),
        (58, "城市"),
        (60, "對抗"),
        (62, "食"),
    ]
    expected_n_gram_text = [
        [(6, "日語")],
        [(8, "進撃")],
        [(9, "の")],
        [(13, "日本")],
        [(14, "漫畫家")],
        [(15, "諫山")],
        [(16, "創")],
        [(17, "創作")],
        [(19, "漫畫")],
        [(20, "作品")],
        [(22, "漫畫")],
        [(24, "2009年")],
        [(25, "9月")],
        [(27, "2021年")],
        [(28, "4月間")],
        [(30, "講談社")],
        [(33, "冊")],
        [(34, "少年")],
        [(35, "Magazine")],
        [(38, "連載")],
        [(40, "故事")],
        [(41, "建立")],
        [(47, "衝突")],
        [(51, "居住")],
        [(54, "高")],
        [(55, "牆")],
        [(56, "包圍")],
        [(58, "城市")],
        [(60, "對抗")],
        [(62, "食")],
    ]

    assertEquals(content_text, expected_content_text, n_gram_text, expected_n_gram_text)


def test_preprocess_not_load_default_stopwords(testcase2, extractor):
    tokenized_text = testcase2["tokenized_text"]
    content_text, n_gram_text = extractor._preprocess(
        tokenized_text,
        load_default=False,
    )
    expected_content_text = [
        (0, "《"),
        (1, "進擊"),
        (2, "的"),
        (3, "巨人"),
        (4, "》"),
        (5, "（"),
        (6, "日語"),
        (7, "："),
        (8, "進撃"),
        (9, "の"),
        (10, "巨人"),
        (11, "）"),
        (12, "是"),
        (13, "日本"),
        (14, "漫畫家"),
        (15, "諫山"),
        (16, "創"),
        (17, "創作"),
        (18, "的"),
        (19, "漫畫"),
        (20, "作品"),
        (21, "。"),
        (22, "漫畫"),
        (23, "於"),
        (24, "2009年"),
        (25, "9月"),
        (26, "至"),
        (27, "2021年"),
        (28, "4月間"),
        (29, "在"),
        (30, "講談社"),
        (31, "《"),
        (32, "別"),
        (33, "冊"),
        (34, "少年"),
        (35, "Magazine"),
        (36, "》"),
        (37, "上"),
        (38, "連載"),
        (39, "。"),
        (40, "故事"),
        (41, "建立"),
        (42, "在"),
        (43, "人類"),
        (44, "與"),
        (45, "巨人"),
        (46, "的"),
        (47, "衝突"),
        (48, "上"),
        (49, "，"),
        (50, "人類"),
        (51, "居住"),
        (52, "在"),
        (53, "由"),
        (54, "高"),
        (55, "牆"),
        (56, "包圍"),
        (57, "的"),
        (58, "城市"),
        (59, "，"),
        (60, "對抗"),
        (61, "會"),
        (62, "食"),
        (63, "人"),
        (64, "的"),
        (65, "巨人"),
        (66, "。"),
    ]
    expected_n_gram_text = [
        [(0, "《")],
        [(1, "進擊")],
        [(2, "的")],
        [(3, "巨人")],
        [(4, "》")],
        [(5, "（")],
        [(6, "日語")],
        [(7, "：")],
        [(8, "進撃")],
        [(9, "の")],
        [(10, "巨人")],
        [(11, "）")],
        [(12, "是")],
        [(13, "日本")],
        [(14, "漫畫家")],
        [(15, "諫山")],
        [(16, "創")],
        [(17, "創作")],
        [(18, "的")],
        [(19, "漫畫")],
        [(20, "作品")],
        [(21, "。")],
        [(22, "漫畫")],
        [(23, "於")],
        [(24, "2009年")],
        [(25, "9月")],
        [(26, "至")],
        [(27, "2021年")],
        [(28, "4月間")],
        [(29, "在")],
        [(30, "講談社")],
        [(31, "《")],
        [(32, "別")],
        [(33, "冊")],
        [(34, "少年")],
        [(35, "Magazine")],
        [(36, "》")],
        [(37, "上")],
        [(38, "連載")],
        [(39, "。")],
        [(40, "故事")],
        [(41, "建立")],
        [(42, "在")],
        [(43, "人類")],
        [(44, "與")],
        [(45, "巨人")],
        [(46, "的")],
        [(47, "衝突")],
        [(48, "上")],
        [(49, "，")],
        [(50, "人類")],
        [(51, "居住")],
        [(52, "在")],
        [(53, "由")],
        [(54, "高")],
        [(55, "牆")],
        [(56, "包圍")],
        [(57, "的")],
        [(58, "城市")],
        [(59, "，")],
        [(60, "對抗")],
        [(61, "會")],
        [(62, "食")],
        [(63, "人")],
        [(64, "的")],
        [(65, "巨人")],
        [(66, "。")],
    ]

    assertEquals(content_text, expected_content_text, n_gram_text, expected_n_gram_text)


def test_preprocess_n_gram(testcase2, extractor):
    tokenized_text = testcase2["tokenized_text"]
    content_text, n_gram_text = extractor._preprocess(
        tokenized_text,
        n_gram=2,
    )
    expected_content_text = [
        (1, "進擊"),
        (3, "巨人"),
        (6, "日語"),
        (8, "進撃"),
        (9, "の"),
        (10, "巨人"),
        (13, "日本"),
        (14, "漫畫家"),
        (15, "諫山"),
        (16, "創"),
        (17, "創作"),
        (19, "漫畫"),
        (20, "作品"),
        (22, "漫畫"),
        (24, "2009年"),
        (25, "9月"),
        (27, "2021年"),
        (28, "4月間"),
        (30, "講談社"),
        (33, "冊"),
        (34, "少年"),
        (35, "Magazine"),
        (38, "連載"),
        (40, "故事"),
        (41, "建立"),
        (43, "人類"),
        (45, "巨人"),
        (47, "衝突"),
        (50, "人類"),
        (51, "居住"),
        (54, "高"),
        (55, "牆"),
        (56, "包圍"),
        (58, "城市"),
        (60, "對抗"),
        (62, "食"),
        (65, "巨人"),
    ]
    expected_n_gram_text = [
        [(1, "進擊"), (3, "巨人")],
        [(3, "巨人"), (6, "日語")],
        [(6, "日語"), (8, "進撃")],
        [(8, "進撃"), (9, "の")],
        [(9, "の"), (10, "巨人")],
        [(10, "巨人"), (13, "日本")],
        [(13, "日本"), (14, "漫畫家")],
        [(14, "漫畫家"), (15, "諫山")],
        [(15, "諫山"), (16, "創")],
        [(16, "創"), (17, "創作")],
        [(17, "創作"), (19, "漫畫")],
        [(19, "漫畫"), (20, "作品")],
        [(20, "作品"), (22, "漫畫")],
        [(22, "漫畫"), (24, "2009年")],
        [(24, "2009年"), (25, "9月")],
        [(25, "9月"), (27, "2021年")],
        [(27, "2021年"), (28, "4月間")],
        [(28, "4月間"), (30, "講談社")],
        [(30, "講談社"), (33, "冊")],
        [(33, "冊"), (34, "少年")],
        [(34, "少年"), (35, "Magazine")],
        [(35, "Magazine"), (38, "連載")],
        [(38, "連載"), (40, "故事")],
        [(40, "故事"), (41, "建立")],
        [(41, "建立"), (43, "人類")],
        [(43, "人類"), (45, "巨人")],
        [(45, "巨人"), (47, "衝突")],
        [(47, "衝突"), (50, "人類")],
        [(50, "人類"), (51, "居住")],
        [(51, "居住"), (54, "高")],
        [(54, "高"), (55, "牆")],
        [(55, "牆"), (56, "包圍")],
        [(56, "包圍"), (58, "城市")],
        [(58, "城市"), (60, "對抗")],
        [(60, "對抗"), (62, "食")],
        [(62, "食"), (65, "巨人")],
    ]

    assertEquals(content_text, expected_content_text, n_gram_text, expected_n_gram_text)
